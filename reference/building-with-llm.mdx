---
title: "Building with LLMs"
description: "Use large language models (LLMs) to accelerate how you integrate SuprSend into your applications"
keywords:
  - suprsend mcp
  - mcp tools suprsend
  - multi-agent communication
  - ai agents suprsend
  - model context protocol
  - llm integration
---

Whether you’re working with AI-assisted editors such as Cursor, Windsurf, or VS Code with Copilot, SuprSend provides dedicated tooling and resources to help LLMs understand and interact with your notification infrastructure more effectively.

## Plain text docs

Every page in the SuprSend documentation can be accessed in plain text format by appending a `.md` extension. For example, this page is available at `building-with-llms.md`.

Plain text pages are especially useful when feeding documentation into an LLM, making it easier for the model to guide you during integration.

We also provide [llms.txt](https://docs.suprsend.com/llms.txt) and [llms-full.txt](https://docs.suprsend.com/llms-full.txt) endpoints, which outline how AI agents and tools can systematically access the plain text versions of our docs.

## SuprSend MCP Server

SuprSend ships an MCP server that exposes SuprSend’s core building blocks—workflows, users, tenants, objects, and preferences—to LLMs and AI agents via the **Model Context Protocol (MCP)**.

With the SuprSend MCP server, you can:

- Generate and refine code using natural language through AI-powered editors and agent tools.  
- Query SuprSend documentation directly to resolve integration and setup questions faster.  
- Build integrations quickly by allowing AI agents to call SuprSend tools without writing custom API wrappers.  
- Trigger and test workflows interactively using plain-language prompts.  

The MCP server connects seamlessly with any MCP-compatible client or agent platform.

Learn more in our [MCP Server docs](/reference/mcp-overview).